{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation Notebook\n",
    "\n",
    "This notebook serves as a way to generate random date in a reproduceable and configurable way. In order to run this notebook make sure the dependencies in requirements.txt are installed.\n",
    "\n",
    "If there are any questions, please email erik.hakansson{at}gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator\n",
    "Will allow easy and reproduceable data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(seed: int, n_continous: int, n_categorical: int, sample_size: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Helper function for generating a random but reproduceable df of specified \n",
    "    amount continous and categorical variables.\n",
    "    \n",
    "    seed: number for reproducing random generations\n",
    "    n_continous: number of wanted continous cols\n",
    "    n_categorical: number of wanted categorical cols (categories == unique english lowercase letters)\n",
    "    sample_size: n rows of generated df\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # genreate continous valued part of df\n",
    "    continous_data = np.random.rand(sample_size, n_continous)\n",
    "    \n",
    "    # generate unique english lowercase letters and sample for categorical vars\n",
    "    categories = list(map(chr, range(97,123)))\n",
    "    categorical_data = np.random.choice(categories, size=(sample_size, n_categorical))\n",
    "\n",
    "    # concatenate to be returned as dataframe\n",
    "    data = np.concatenate((continous_data, categorical_data), axis=1)\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate DF according to instructions\n",
    "\n",
    "Let's generate our data and make sure the columns are nicely labeled. Finally, we will export it to a csv file. This will enable a more modular (and realistic) way of stepping through the data science process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate df and rename columns for more clarity\n",
    "df = generate_dataset(seed=SEED, n_continous=3, n_categorical=1, sample_size=10000)\n",
    "\n",
    "# edit feature names to be explciti, and denote one continous col as the prediction target\n",
    "feature_names = ['feature' + str(col) for col in df.columns]\n",
    "feature_names[0] = 'target'\n",
    "df.columns = feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3745401188473625</td>\n",
       "      <td>0.9507143064099162</td>\n",
       "      <td>0.7319939418114051</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5986584841970366</td>\n",
       "      <td>0.15601864044243652</td>\n",
       "      <td>0.15599452033620265</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05808361216819946</td>\n",
       "      <td>0.8661761457749352</td>\n",
       "      <td>0.6011150117432088</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7080725777960455</td>\n",
       "      <td>0.020584494295802447</td>\n",
       "      <td>0.9699098521619943</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8324426408004217</td>\n",
       "      <td>0.21233911067827616</td>\n",
       "      <td>0.18182496720710062</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                target              feature1             feature2 feature3\n",
       "0   0.3745401188473625    0.9507143064099162   0.7319939418114051        m\n",
       "1   0.5986584841970366   0.15601864044243652  0.15599452033620265        f\n",
       "2  0.05808361216819946    0.8661761457749352   0.6011150117432088        a\n",
       "3   0.7080725777960455  0.020584494295802447   0.9699098521619943        f\n",
       "4   0.8324426408004217   0.21233911067827616  0.18182496720710062        m"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv for a more realistic experience.\n",
    "DATA_DIR = \"../data\"\n",
    "file_name = f\"testData-{SEED}-raw.csv\"\n",
    "relative_path = os.path.join(DATA_DIR, file_name)\n",
    "\n",
    "df.to_csv(relative_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We've only just begun...\n",
    "Now that we've generated data, the only step between developing a model and us is a little bit of preprocessing. Do note that we're skipping an EDA step, as we are dealing with random data after all...\n",
    "\n",
    "Please head over to the <code>model.ipynb</code> for the continuation :)\n",
    "\n",
    "##### NOTE: if you're looking for signs of feature engineering, we'll get there in the model notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
